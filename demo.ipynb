{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nq5DUjCItIFJ"
      },
      "source": [
        "# LightGlue Demo\n",
        "In this notebook we match two pairs of images using LightGlue with early stopping and point pruning."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xx1hmB4ue7b",
        "outputId": "13c0a94e-058a-4f14-ca21-92bd1d4473d7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0i8YVRwEwLGx",
        "outputId": "70a04339-0435-4720-f212-2a38eecfdf3f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip \"gallery.zip\" -d \"gallery\""
      ],
      "metadata": {
        "id": "lMSHCUxovif8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "seL2hUpatIFL",
        "outputId": "820e105a-8065-4d23-e1f1-1b682f78a81d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/LightGlue\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building editable for lightglue (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# If we are on colab: this clones the repo and installs the dependencies\n",
        "from pathlib import Path\n",
        "\n",
        "if Path.cwd().name != \"LightGlue\":\n",
        "    !git clone --quiet https://github.com/cvg/LightGlue/\n",
        "    %cd LightGlue\n",
        "    !pip install --progress-bar off --quiet -e .\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from lightglue import LightGlue, SuperPoint, DISK\n",
        "from lightglue.utils import load_image, rbd\n",
        "from lightglue import viz2d\n",
        "import torch\n",
        "import numpy as np\n",
        "from lightglue import match_pair\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2\n",
        "import sys"
      ],
      "metadata": {
        "id": "_6oh9ryw8ChC"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.set_grad_enabled(False)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # 'mps', 'cpu'\n",
        "\n",
        "extractor = SuperPoint(max_num_keypoints=2048).eval().to(device)  # load the extractor\n",
        "matcher = LightGlue(features=\"superpoint\").eval().to(device)\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fF1QsSzA-X_z",
        "outputId": "6ff6c30e-f0da-49cc-8b00-6dd61a6dccd5"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/cvg/LightGlue/releases/download/v0.1_arxiv/superpoint_v1.pth\" to /root/.cache/torch/hub/checkpoints/superpoint_v1.pth\n",
            "100%|██████████| 4.96M/4.96M [00:00<00:00, 331MB/s]\n",
            "Downloading: \"https://github.com/cvg/LightGlue/releases/download/v0.1_arxiv/superpoint_lightglue.pth\" to /root/.cache/torch/hub/checkpoints/superpoint_lightglue_v0-1_arxiv.pth\n",
            "100%|██████████| 45.3M/45.3M [00:01<00:00, 40.8MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_path = Path(\"gallery/gallery/query_boxed\")\n",
        "gallery_path = Path(\"gallery/gallery/gallery\")\n",
        "\n",
        "file_list = os.listdir(\"gallery/gallery/query_boxed/\")\n",
        "file_list.sort(key=lambda x:x.split(\".\")[0])\n",
        "\n",
        "for i, file_name in enumerate(file_list):\n",
        "    query_image = load_image(query_path / file_name)\n",
        "    # cv2.imread(str(query_path / file_name))\n",
        "    file_list = os.listdir(str(gallery_path))\n",
        "    scores = []\n",
        "    for i, file_name1 in enumerate(file_list):\n",
        "        percentage = round(i / len(file_list) * 100)\n",
        "        print(\"\\r文件处理进度: {}%: \".format(percentage), \"▓\" * (percentage // 2), end=\"\")\n",
        "        sys.stdout.flush()\n",
        "        gallery_image = load_image(gallery_path / file_name1)\n",
        "        _, _, matches = match_pair(extractor, matcher, query_image.cuda(), gallery_image.cuda())\n",
        "        if len(matches['scores']) > 0:\n",
        "            score = np.mean(np.array(matches['scores']))\n",
        "        else: score=0\n",
        "        scores.append((file_name1.split(\".\")[0], score))\n",
        "    scores.sort(key=lambda x: x[1], reverse=True)\n",
        "    with open('ORB_deep.txt', 'a', encoding='utf-8') as file:\n",
        "        file.write(\"Q\" + str(int(file_name.split('.')[0])+1) + \": \")\n",
        "        order = \"\"\n",
        "        for num, _ in scores:\n",
        "            order = order + num + \" \"\n",
        "        file.write(order)\n",
        "        file.write(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNem6zss8NOr",
        "outputId": "41b1a367-09d5-427a-f397-e435856ff65a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "文件处理进度: 49%:  ▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.8"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}